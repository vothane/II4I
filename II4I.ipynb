{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "II4I.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vothane/II4I/blob/master/II4I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK-Hm5YzM_Y2",
        "colab_type": "text"
      },
      "source": [
        "**Lets go Bruins. All eyes on center.**\n",
        "\n",
        "![](https://https://media1.giphy.com/media/hJjTwuJjjsVgc/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztdTbEQpNQrI",
        "colab_type": "text"
      },
      "source": [
        "![](https://media1.giphy.com/media/hJjTwuJjjsVgc/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HUqNWmAuoaG",
        "colab_type": "text"
      },
      "source": [
        "To save time and headache from debugging/refactoring original code, instead get/steal  [code](https://www.kaggle.com/kmader/capsulenet-on-mnist/notebook) from **Kevin Mader** who in turn got it from Xifeng Guo ([github](https://www.kaggle.com/kmader/capsulenet-on-mnist/notebook)) who in turn ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRX3bXfNXzZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJOO6AVVv_WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss\n",
        "    inputs: shape=[dim_1, ..., dim_{n-1}, dim_n]\n",
        "    output: shape=[dim_1, ..., dim_{n-1}]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, d1, d2] by the max value in axis=1.\n",
        "    Output shape: [None, d2]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # use true label to select target capsule, shape=[batch_size, num_capsule]\n",
        "        if type(inputs) is list:  # true label is provided with shape = [batch_size, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of vectors of capsules\n",
        "            x = inputs\n",
        "            # Enlarge the range of values in x to make max(new_x)=1 and others < 0\n",
        "            x = (x - K.max(x, 1, True)) / K.epsilon() + 1\n",
        "            mask = K.clip(x, 0, 1)  # the max value in x clipped to 1 and other to 0\n",
        "\n",
        "        # masked inputs, shape = [batch_size, dim_vector]\n",
        "        inputs_masked = K.batch_dot(inputs, mask, [1, 1])\n",
        "        return inputs_masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][-1]])\n",
        "        else:\n",
        "            return tuple([None, input_shape[-1]])\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm)\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_vector] and output shape = \\\n",
        "    [None, num_capsule, dim_vector]. For Dense Layer, input_dim_vector = dim_vector = 1.\n",
        "    \n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_vector: dimension of the output vectors of the capsules in this layer\n",
        "    :param num_routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_vector, num_routing=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_vector = dim_vector\n",
        "        self.num_routing = num_routing\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_vector]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_vector = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dim_vector],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        # Coupling coefficient. The redundant dimensions are just to facilitate subsequent matrix calculation.\n",
        "        self.bias = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1],\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    name='bias',\n",
        "                                    trainable=False)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_vector]\n",
        "        # Expand dims to [None, input_num_capsule, 1, 1, input_dim_vector]\n",
        "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # Now it has shape = [None, input_num_capsule, num_capsule, 1, input_dim_vector]\n",
        "        inputs_tiled = K.tile(inputs_expand, [1, 1, self.num_capsule, 1, 1])\n",
        "\n",
        "        \"\"\"  \n",
        "        # Compute `inputs * W` by expanding the first dim of W. More time-consuming and need batch_size.\n",
        "        # Now W has shape  = [batch_size, input_num_capsule, num_capsule, input_dim_vector, dim_vector]\n",
        "        w_tiled = K.tile(K.expand_dims(self.W, 0), [self.batch_size, 1, 1, 1, 1])\n",
        "        \n",
        "        # Transformed vectors, inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
        "        inputs_hat = K.batch_dot(inputs_tiled, w_tiled, [4, 3])\n",
        "        \"\"\"\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0. This is faster but requires Tensorflow.\n",
        "        # inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
        "        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n",
        "                             elems=inputs_tiled,\n",
        "                             initializer=K.zeros([self.input_num_capsule, self.num_capsule, 1, self.dim_vector]))\n",
        "        \"\"\"\n",
        "        # Routing algorithm V1. Use tf.while_loop in a dynamic way.\n",
        "        def body(i, b, outputs):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
        "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
        "            b = b + K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "            return [i-1, b, outputs]\n",
        "\n",
        "        cond = lambda i, b, inputs_hat: i > 0\n",
        "        loop_vars = [K.constant(self.num_routing), self.bias, K.sum(inputs_hat, 1, keepdims=True)]\n",
        "        _, _, outputs = tf.while_loop(cond, body, loop_vars)\n",
        "        \"\"\"\n",
        "        # Routing algorithm V2. Use iteration. V2 and V1 both work without much difference on performance\n",
        "        assert self.num_routing > 0, 'The num_routing should be > 0.'\n",
        "        for i in range(self.num_routing):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
        "            # outputs.shape=[None, 1, num_capsule, 1, dim_vector]\n",
        "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
        "\n",
        "            # last iteration needs not compute bias which will not be passed to the graph any more anyway.\n",
        "            if i != self.num_routing - 1:\n",
        "                # self.bias = K.update_add(self.bias, K.sum(inputs_hat * outputs, [0, -1], keepdims=True))\n",
        "                self.bias += K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "            # tf.summary.histogram('BigBee', self.bias)  # for debugging\n",
        "        return K.reshape(outputs, [-1, self.num_capsule, self.dim_vector])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_vector])\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_vector: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_vector]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n",
        "    return layers.Lambda(squash)(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Xf5sOcwDce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers, models\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def CapsNet(input_shape, n_class, num_routing):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 4d, [None, width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param num_routing: number of routing iterations\n",
        "    :return: A Keras Model with 2 inputs and 2 outputs\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_vector]\n",
        "    primarycaps = PrimaryCap(conv1, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_vector=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='out_caps')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer.\n",
        "    x_recon = layers.Dense(512, activation='relu')(masked)\n",
        "    x_recon = layers.Dense(1024, activation='relu')(x_recon)\n",
        "    x_recon = layers.Dense(784, activation='sigmoid')(x_recon)\n",
        "    x_recon = layers.Reshape(target_shape=[28, 28, 1], name='out_recon')(x_recon)\n",
        "\n",
        "    # two-input-two-output keras Model\n",
        "    return models.Model([x, y], [out_caps, x_recon])\n",
        "  \n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1CSOpUOVaH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff22b604-3b16-4208-869c-de6b45d0fb38"
      },
      "source": [
        "# define model\n",
        "model = CapsNet(input_shape=[28, 28, 1],\n",
        "                n_class=10,\n",
        "                num_routing=3)\n",
        "\n",
        "try:\n",
        "    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "except Exception as e:\n",
        "    print('No fancy plot {}'.format(e))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMfYaFL1V1Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "y_train = to_categorical(y_train.astype('float32'))\n",
        "y_test = to_categorical(y_test.astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miZdJKyXWsaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, data, epoch_size_frac=1.0):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger('log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint('weights-{epoch:02d}.h5',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., 0.0005],\n",
        "                  metrics={'out_caps': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint])\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------------------Begin: Training with data augmentation -----------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
        "    model.fit_generator(generator=train_generator(x_train, y_train, 64, 0.1),\n",
        "                        steps_per_epoch=int(epoch_size_frac*y_train.shape[0] / 64),\n",
        "                        epochs=1,\n",
        "                        validation_data=[[x_test, y_test], [y_test, x_test]],\n",
        "                        callbacks=[log, checkpoint, lr_decay])\n",
        "    # -----------------------------------End: Training with data augmentation -----------------------------------#\n",
        "\n",
        "    model.save_weights('trained_model.h5')\n",
        "    print('Trained model saved to \\'trained_model.h5\\'')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uefH3zexWwLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b604cde2-39bc-4a49-9aad-cb720421a214"
      },
      "source": [
        "train(model=model, data=((x_train, y_train), (x_test[:60], y_test[:60])), \n",
        "      epoch_size_frac = 0.5) "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "468/468 [==============================] - 1456s 3s/step - loss: 0.1443 - out_caps_loss: 0.1443 - out_recon_loss: 0.1294 - out_caps_acc: 0.8500 - val_loss: 0.0238 - val_out_caps_loss: 0.0238 - val_out_recon_loss: 0.0638 - val_out_caps_acc: 1.0000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02381, saving model to weights-01.h5\n",
            "Trained model saved to 'trained_model.h5'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f16d0d26630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56y7_x9xcJZ0",
        "colab_type": "text"
      },
      "source": [
        "With **MNIST** data looks promising. Lets not get carried away tho.\n",
        "\n",
        "![](https://media.giphy.com/media/TrRKdBUdaxYDC/giphy-downsized-large.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPBa5KuAdlYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5f092de0-64b4-4ec9-823a-a88953c54c54"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "y_train = to_categorical(y_train.astype('float32'))\n",
        "y_test = to_categorical(y_test.astype('float32'))\n",
        "\n",
        "model2 = CapsNet(input_shape=[28, 28, 1],\n",
        "                n_class=10,\n",
        "                num_routing=3)\n",
        "\n",
        "train(model=model2, data=((x_train, y_train), (x_test[:60], y_test[:60])), \n",
        "      epoch_size_frac = 0.5) "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "468/468 [==============================] - 1601s 3s/step - loss: 0.2188 - out_caps_loss: 0.2187 - out_recon_loss: 0.1210 - out_caps_acc: 0.6986 - val_loss: 0.2235 - val_out_caps_loss: 0.2235 - val_out_recon_loss: 0.0879 - val_out_caps_acc: 0.6833\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.22352, saving model to weights-01.h5\n",
            "Trained model saved to 'trained_model.h5'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f16cfe0d390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CBN6RlgdCzJ",
        "colab_type": "text"
      },
      "source": [
        "With **Fashion MNIST** (a more revelant real life dataset) looks a little more promising. Lets get carried away.\n",
        "\n",
        "![](https://i.imgur.com/2b2tZg4.jpg)"
      ]
    }
  ]
}